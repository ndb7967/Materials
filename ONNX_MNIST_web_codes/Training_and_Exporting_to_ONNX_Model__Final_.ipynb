{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>MNIST ONNX Project</b>\n",
        "\n",
        "* This code is from PyTorch's MNIST example (with only a few changes).\n",
        "  * <b>Reference</b>: https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "* 본 코드는 MNIST 분류 모델을 학습한 뒤에, <b>오닉스(ONNX) 파일</b>로 내보내기까지 하는 코드입니다.\n",
        "  * GPU를 사용하기 때문에, 런타임 유형을 GPU로 변경한 뒤에 실습을 진행합니다."
      ],
      "metadata": {
        "id": "wb-ZzPSJaVu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Load Libraries</b>"
      ],
      "metadata": {
        "id": "8g64_X7FajCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # PyTorch의 기본적인 라이브러리\n",
        "\n",
        "import torch.nn as nn # Neural Network 그 자체\n",
        "import torch.nn.functional as F # 다양한 함수(ReLU 등) 제공하는 라이브러리\n",
        "import torch.optim as optim # 최적화(optimizer) 라이브러리\n",
        "\n",
        "import torchvision # PyTorch를 이용해서 이미지/동영상을 처리하고자 할 때\n",
        "from torchvision import datasets, transforms\n",
        "# datasets: MNIST, CIFAR-10 등 다양한 데이터를 다운로드 및 불러와 사용\n",
        "# transforms: 이미지 회전, 크기 변경 등 변형(transformation)\n",
        "\n",
        "# 학습하는 과정에서 학습률(learning rate)를 점진적으로 줄여나가는 방식 사용\n",
        "# StepLR은 특정한 epoch가 지날 때마다 단계적으로 감소시키는 방식\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "siX19VAfairj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Define Hyperparameters</b>\n",
        "\n"
      ],
      "metadata": {
        "id": "1g3AmMUObfvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 온점(.)으로 속성 값을 기입하도록 해주는 라이브러리\n",
        "from types import SimpleNamespace\n",
        "\n",
        "args = SimpleNamespace()\n",
        "\n",
        "# 실질적인 하이퍼 파라미터 설정\n",
        "args.batch_size = 512 # input batch size for training (default: 512)\n",
        "args.test_batch_size = 1000 # input batch size for testing (default: 1000)\n",
        "args.epochs = 10 # number of epochs to train (default: 10)\n",
        "args.lr = 1.0 # learning rate (default: 1.0)\n",
        "# 특정한 주기로 learning rate을 감소시킬 때, 몇 배수만큼씩 줄여나갈지\n",
        "args.gamma = 0.7 # learning rate step gamma (default: 0.7)\n",
        "# GPU를 사용할 것이기 때문에, 아래 값은 False로 기입\n",
        "args.no_cuda = False # disables CUDA training\n",
        "args.seed = 1 # random seed (default: 1)\n",
        "args.log_interval = 10 # how many batches to wait before logging training status\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "# visualize the argument parameters\n",
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HcY362vbkxR",
        "outputId": "da41d10d-8a08-47b0-de20-1dda553c0979"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(batch_size=512,\n",
              "          test_batch_size=1000,\n",
              "          epochs=10,\n",
              "          lr=1.0,\n",
              "          gamma=0.7,\n",
              "          no_cuda=False,\n",
              "          seed=1,\n",
              "          log_interval=10)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Define Models</b>"
      ],
      "metadata": {
        "id": "25lBgTEmarXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1mpLl4VdaRTv"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 입력 채널: 1, 출력 채널(커널의 개수): 32, 커널 크기: 3, stride: 1\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        # 입력 채널: 32, 출력 채널(커널의 개수): 64, 커널 크기: 3, stride: 1\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, 28, 28, 1)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        # x: (batch_size, 26, 26, 32)\n",
        "        x = self.conv2(x)\n",
        "        # x: (batch_size, 24, 24, 64)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        # x: (batch_size, 12, 12, 64)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # x: (batch_size, 9216)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        # x: (batch_size, 128)\n",
        "        x = self.fc2(x)\n",
        "        # x: (batch_size, 10)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Model Training Libraries</b>"
      ],
      "metadata": {
        "id": "GzRC0OpvbK7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    # 10개의 클래스를 가지므로, cross-entropy 손실(loss)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.train() # 모델을 학습 모드로 변경\n",
        "    # 매 배치 단위로 데이터를 확인\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # 입력 이미지와 정답 레이블을 GPU로 보내주기\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad() # 모델의 가중치 기울기 초기화\n",
        "        # 모델에 입력 이미지를 넣은 뒤에 손실(loss)을 계산\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        # 역전파(back-propagation)\n",
        "        loss.backward()\n",
        "        optimizer.step() # 모델의 가중치 업데이트\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    # 10개의 클래스를 가지므로, cross-entropy 손실(loss)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.eval() # 모델을 학습 모드로 변경\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    # 모델을 학습하지 않고, 단순히 평가만 할 것이기 때문에 기울기 계산 X\n",
        "    with torch.no_grad():\n",
        "        # 매 배치 단위로 데이터를 확인\n",
        "        for data, target in test_loader:\n",
        "            # 입력 이미지와 정답 레이블을 GPU로 보내주기\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # 모델에 입력 이미지를 넣은 뒤에 정확도(accuracy) 계산\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "RVJ2pJe5bNTR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Define the Data Loader</b>"
      ],
      "metadata": {
        "id": "jLRKHbKvecuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연구 목적의 상황과 다르게, 배포된 모델에 사람들이 입력 진행\n",
        "train_transform = transforms.Compose([\n",
        "    # add random transformations to the image\n",
        "    # 다양한 각도와 크기에 대하여 강건할(robust) 필요가 있다.\n",
        "    transforms.RandomAffine( # 랜덤하게 이미지를 변환\n",
        "        degrees=10,\n",
        "        translate=(0.0, 0.2),\n",
        "        scale=(0.5, 1.2),\n",
        "        shear=(-10, 10, -10, 10)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# 테스트할 때는 입력 받은 이미지를 그대로 모델에 넣어주기\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, transform=test_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "ZTZCdVsBegY5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Preview Dataset</b>"
      ],
      "metadata": {
        "id": "RmzA6pJff3bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습할 이미지가 어떻게 생겼는지 시각화\n",
        "inputs_batch, labels_batch = next(iter(train_loader))\n",
        "grid = torchvision.utils.make_grid(inputs_batch, nrow=40, pad_value=1)\n",
        "torchvision.utils.save_image(grid, 'inputs_batch_preview.png')"
      ],
      "metadata": {
        "id": "Zi60K0Tnf5oR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Run the Program</b>"
      ],
      "metadata": {
        "id": "p1VBTPfCc1BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 실험할 때마다 결과가 달라지는 걸 원하지 않으므로\n",
        "# 재현성(reproduciability)을 위해 시드(seed) 값 설정\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "# GPU로 모델을 보내주어 학습할 것이기 때문에\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# 실제로 학습할 모델을 초기화\n",
        "model = Net().to(device)\n",
        "# 학습할 때 사용할 최적화(optimizer) 도구\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
        "\n",
        "# 학습 진행\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "# <테스트 정확도가 낮을 수 있음>\n",
        "# 이유: 테스트 데이터셋은 변형이 없는 올곧은 데이터로만 구성\n",
        "# 우리는 현실 세계의 배포를 위해 데이터 증진을 강하게 적용\n",
        "torch.save(model.state_dict(), \"pytorch_model.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kQh-Is6c2fR",
        "outputId": "7d0db852-8456-4d58-d62a-e9b756e25ea5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.313355\n",
            "Train Epoch: 1 [5120/60000 (8%)]\tLoss: 1.917524\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.838268\n",
            "Train Epoch: 1 [15360/60000 (25%)]\tLoss: 1.450712\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.370872\n",
            "Train Epoch: 1 [25600/60000 (42%)]\tLoss: 0.892754\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.747283\n",
            "Train Epoch: 1 [35840/60000 (59%)]\tLoss: 0.686359\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.677472\n",
            "Train Epoch: 1 [46080/60000 (76%)]\tLoss: 0.657784\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.582088\n",
            "Train Epoch: 1 [56320/60000 (93%)]\tLoss: 0.541259\n",
            "\n",
            "Test set: Average loss: 0.0003, Accuracy: 9131/10000 (91%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.672697\n",
            "Train Epoch: 2 [5120/60000 (8%)]\tLoss: 0.532947\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.563783\n",
            "Train Epoch: 2 [15360/60000 (25%)]\tLoss: 0.474682\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.432300\n",
            "Train Epoch: 2 [25600/60000 (42%)]\tLoss: 0.451109\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.482860\n",
            "Train Epoch: 2 [35840/60000 (59%)]\tLoss: 0.361907\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.394926\n",
            "Train Epoch: 2 [46080/60000 (76%)]\tLoss: 0.514306\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.438915\n",
            "Train Epoch: 2 [56320/60000 (93%)]\tLoss: 0.453426\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9628/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.388793\n",
            "Train Epoch: 3 [5120/60000 (8%)]\tLoss: 0.300985\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.375752\n",
            "Train Epoch: 3 [15360/60000 (25%)]\tLoss: 0.435050\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.272653\n",
            "Train Epoch: 3 [25600/60000 (42%)]\tLoss: 0.473055\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.350903\n",
            "Train Epoch: 3 [35840/60000 (59%)]\tLoss: 0.318464\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.326451\n",
            "Train Epoch: 3 [46080/60000 (76%)]\tLoss: 0.273387\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.319237\n",
            "Train Epoch: 3 [56320/60000 (93%)]\tLoss: 0.391356\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9773/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.358348\n",
            "Train Epoch: 4 [5120/60000 (8%)]\tLoss: 0.291748\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.355680\n",
            "Train Epoch: 4 [15360/60000 (25%)]\tLoss: 0.269723\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.286272\n",
            "Train Epoch: 4 [25600/60000 (42%)]\tLoss: 0.249520\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.305789\n",
            "Train Epoch: 4 [35840/60000 (59%)]\tLoss: 0.346347\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.341430\n",
            "Train Epoch: 4 [46080/60000 (76%)]\tLoss: 0.304615\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.338691\n",
            "Train Epoch: 4 [56320/60000 (93%)]\tLoss: 0.306729\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9776/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.280227\n",
            "Train Epoch: 5 [5120/60000 (8%)]\tLoss: 0.327364\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.308052\n",
            "Train Epoch: 5 [15360/60000 (25%)]\tLoss: 0.297313\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.267611\n",
            "Train Epoch: 5 [25600/60000 (42%)]\tLoss: 0.343347\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.226906\n",
            "Train Epoch: 5 [35840/60000 (59%)]\tLoss: 0.330219\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.293406\n",
            "Train Epoch: 5 [46080/60000 (76%)]\tLoss: 0.225117\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.244076\n",
            "Train Epoch: 5 [56320/60000 (93%)]\tLoss: 0.234738\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.249415\n",
            "Train Epoch: 6 [5120/60000 (8%)]\tLoss: 0.282087\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.256367\n",
            "Train Epoch: 6 [15360/60000 (25%)]\tLoss: 0.322889\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.221444\n",
            "Train Epoch: 6 [25600/60000 (42%)]\tLoss: 0.241330\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.217539\n",
            "Train Epoch: 6 [35840/60000 (59%)]\tLoss: 0.284919\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.263773\n",
            "Train Epoch: 6 [46080/60000 (76%)]\tLoss: 0.227185\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.262060\n",
            "Train Epoch: 6 [56320/60000 (93%)]\tLoss: 0.224569\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.197469\n",
            "Train Epoch: 7 [5120/60000 (8%)]\tLoss: 0.250009\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.208541\n",
            "Train Epoch: 7 [15360/60000 (25%)]\tLoss: 0.279018\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.240518\n",
            "Train Epoch: 7 [25600/60000 (42%)]\tLoss: 0.272201\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.270539\n",
            "Train Epoch: 7 [35840/60000 (59%)]\tLoss: 0.264324\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.313527\n",
            "Train Epoch: 7 [46080/60000 (76%)]\tLoss: 0.219797\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.265217\n",
            "Train Epoch: 7 [56320/60000 (93%)]\tLoss: 0.230080\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.299127\n",
            "Train Epoch: 8 [5120/60000 (8%)]\tLoss: 0.254053\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.177838\n",
            "Train Epoch: 8 [15360/60000 (25%)]\tLoss: 0.340631\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.309300\n",
            "Train Epoch: 8 [25600/60000 (42%)]\tLoss: 0.352068\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.237870\n",
            "Train Epoch: 8 [35840/60000 (59%)]\tLoss: 0.229062\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.244394\n",
            "Train Epoch: 8 [46080/60000 (76%)]\tLoss: 0.289124\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.180731\n",
            "Train Epoch: 8 [56320/60000 (93%)]\tLoss: 0.185138\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 9856/10000 (99%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.287608\n",
            "Train Epoch: 9 [5120/60000 (8%)]\tLoss: 0.214159\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.273505\n",
            "Train Epoch: 9 [15360/60000 (25%)]\tLoss: 0.250949\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.245132\n",
            "Train Epoch: 9 [25600/60000 (42%)]\tLoss: 0.267780\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.247286\n",
            "Train Epoch: 9 [35840/60000 (59%)]\tLoss: 0.258409\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.201977\n",
            "Train Epoch: 9 [46080/60000 (76%)]\tLoss: 0.304041\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.242679\n",
            "Train Epoch: 9 [56320/60000 (93%)]\tLoss: 0.201180\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9846/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.267639\n",
            "Train Epoch: 10 [5120/60000 (8%)]\tLoss: 0.214423\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.290840\n",
            "Train Epoch: 10 [15360/60000 (25%)]\tLoss: 0.253592\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.231318\n",
            "Train Epoch: 10 [25600/60000 (42%)]\tLoss: 0.287027\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.270156\n",
            "Train Epoch: 10 [35840/60000 (59%)]\tLoss: 0.236308\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.260574\n",
            "Train Epoch: 10 [46080/60000 (76%)]\tLoss: 0.197509\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.220999\n",
            "Train Epoch: 10 [56320/60000 (93%)]\tLoss: 0.226189\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 9845/10000 (98%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Convert to ONNX Model</b>"
      ],
      "metadata": {
        "id": "ImHZeFakdGwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ONNX 파일로 내보내기 위해서 ONNX 라이브러리 설치\n",
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX4Q9vZok_cP",
        "outputId": "5da13455-2b60-4973-c02e-078e3431a510"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 오닉스(onnx) 배포 목적의 코드 작성\n",
        "MEAN = 0.1307 # 원래 데이터 로더에 있던 코드\n",
        "STANDARD_DEVIATION = 0.3081 # 원래 데이터 로더에 있던 코드\n",
        "\n",
        "\n",
        "class InferenceNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(InferenceNet, self).__init__()\n",
        "    # 입력 채널: 1, 출력 채널(커널의 개수): 32, 커널 크기: 3, stride: 1\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "    # 입력 채널: 32, 출력 채널(커널의 개수): 64, 커널 크기: 3, stride: 1\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.dropout1 = nn.Dropout2d(0.25)\n",
        "    self.dropout2 = nn.Dropout2d(0.5)\n",
        "    self.fc1 = nn.Linear(9216, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # 데이터 전처리 부분이 forward() 함수 앞쪽에 존재\n",
        "    # <핵심> 데이터 전처리를 여기에 넣음\n",
        "    # 웹 사이트의 JavaScript 입력 이미지 크기가 (280 X 280 X 4)\n",
        "    # 채널이 4인 이유는? (RGBA) 이므로\n",
        "    x = x.reshape(280, 280, 4)\n",
        "    # 흑백 이미지로 만드는 코드\n",
        "    x = torch.narrow(x, dim=2, start=3, length=1)\n",
        "    # PyTorch Vision의 입력은 항상 다음과 같다.\n",
        "    # (batch_size, channel_size, width, height)\n",
        "    x = x.reshape(1, 1, 280, 280)\n",
        "    # 학습한 모델은 (28 X 28)의 크기를 받기 때문에 조절\n",
        "    x = F.avg_pool2d(x, 10, stride=10)\n",
        "    x = x / 255 # PyTorch는 [0, 1]의 값만 받으므로\n",
        "    # 정규화(normalization)\n",
        "    x = (x - MEAN) / STANDARD_DEVIATION\n",
        "\n",
        "    # x: (batch_size, 28, 28, 1)\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    # x: (batch_size, 26, 26, 32)\n",
        "    x = self.conv2(x)\n",
        "    # x: (batch_size, 24, 24, 64)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout1(x)\n",
        "    # x: (batch_size, 12, 12, 64)\n",
        "    x = torch.flatten(x, 1)\n",
        "    # x: (batch_size, 9216)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout2(x)\n",
        "    # x: (batch_size, 128)\n",
        "    x = self.fc2(x)\n",
        "    # x: (batch_size, 10)\n",
        "    # 배포할 때는 확률(probability)을 뱉는 것이 이상적\n",
        "    # 소프트맥스(softmax)를 거친 결과를 반환\n",
        "    output = F.softmax(x, dim=1)\n",
        "    return output"
      ],
      "metadata": {
        "id": "LY1DMzZFdw3J"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 추론(inference) 목적의 네트워크를 초기화한다.\n",
        "pytorch_model = InferenceNet()\n",
        "\n",
        "# 기본적으로 model의 가중치(__init__)의 구조가 일치한다면, 불러올 수 있다.\n",
        "# forward() 함수의 형식이 달라도 정상적으로 불러오는 것이 가능하다.\n",
        "pytorch_model.load_state_dict(torch.load('pytorch_model.pt'))\n",
        "pytorch_model.eval()\n",
        "\n",
        "dummy_input = torch.zeros(280 * 280 * 4)\n",
        "\n",
        "pytorch_model(dummy_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHYh8FrldIds",
        "outputId": "26985039-6089-4c15-ec48-39090130b8e5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1405e-04, 9.9968e-01, 8.0074e-07, 1.3354e-06, 2.1442e-05, 9.2801e-05,\n",
              "         3.8494e-05, 5.0200e-05, 3.1511e-07, 5.0974e-07]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실제 ONNX 파일로 내보내기\n",
        "torch.onnx.export(pytorch_model, dummy_input, 'onnx_model.onnx', verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tddlxII9Xppo",
        "outputId": "bbb67d72-9b5c-4dc1-e2a5-34273776899f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}