{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>MNIST ONNX Project</b>\n",
        "\n",
        "* This code is from PyTorch's MNIST example (with only a few changes).\n",
        "  * <b>Reference</b>: https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "* 본 코드는 MNIST 분류 모델을 학습한 뒤에, <b>오닉스(ONNX) 파일</b>로 내보내기까지 하는 코드입니다.\n",
        "  * GPU를 사용하기 때문에, 런타임 유형을 GPU로 변경한 뒤에 실습을 진행합니다."
      ],
      "metadata": {
        "id": "wb-ZzPSJaVu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Load Libraries</b>"
      ],
      "metadata": {
        "id": "8g64_X7FajCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # PyTorch의 기본적인 라이브러리\n",
        "\n",
        "import torch.nn as nn # Neural Network 그 자체\n",
        "import torch.nn.functional as F # 다양한 함수(ReLU 등) 제공하는 라이브러리\n",
        "import torch.optim as optim # 최적화(optimizer) 라이브러리\n",
        "\n",
        "import torchvision # PyTorch를 이용해서 이미지/동영상을 처리하고자 할 때\n",
        "from torchvision import datasets, transforms\n",
        "# datasets: MNIST, CIFAR-10 등 다양한 데이터를 다운로드 및 불러와 사용\n",
        "# transforms: 이미지 회전, 크기 변경 등 변형(transformation)\n",
        "\n",
        "# 학습하는 과정에서 학습률(learning rate)를 점진적으로 줄여나가는 방식 사용\n",
        "# StepLR은 특정한 epoch가 지날 때마다 단계적으로 감소시키는 방식\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "siX19VAfairj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Define Hyperparameters</b>\n",
        "\n"
      ],
      "metadata": {
        "id": "1g3AmMUObfvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 온점(.)으로 속성 값을 기입하도록 해주는 라이브러리\n",
        "from types import SimpleNamespace\n",
        "\n",
        "args = SimpleNamespace()\n",
        "\n",
        "# 실질적인 하이퍼 파라미터 설정\n",
        "args.batch_size = 512 # input batch size for training (default: 512)\n",
        "args.test_batch_size = 1000 # input batch size for testing (default: 1000)\n",
        "args.epochs = 10 # number of epochs to train (default: 10)\n",
        "args.lr = 1.0 # learning rate (default: 1.0)\n",
        "# 특정한 주기로 learning rate을 감소시킬 때, 몇 배수만큼씩 줄여나갈지\n",
        "args.gamma = 0.7 # learning rate step gamma (default: 0.7)\n",
        "# GPU를 사용할 것이기 때문에, 아래 값은 False로 기입\n",
        "args.no_cuda = False # disables CUDA training\n",
        "args.seed = 1 # random seed (default: 1)\n",
        "args.log_interval = 10 # how many batches to wait before logging training status\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "# visualize the argument parameters\n",
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HcY362vbkxR",
        "outputId": "651a3de9-9809-4993-f261-52e9f565d6af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(batch_size=512,\n",
              "          test_batch_size=1000,\n",
              "          epochs=10,\n",
              "          lr=1.0,\n",
              "          gamma=0.7,\n",
              "          no_cuda=False,\n",
              "          seed=1,\n",
              "          log_interval=10)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Define Models</b>"
      ],
      "metadata": {
        "id": "25lBgTEmarXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mpLl4VdaRTv"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 입력 채널: 1, 출력 채널(커널의 개수): 32, 커널 크기: 3, stride: 1\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
        "        # 입력 채널: 32, 출력 채널(커널의 개수): 64, 커널 크기: 3, stride: 1\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, 28, 28, 1)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        # x: (batch_size, 26, 26, 32)\n",
        "        x = self.conv2(x)\n",
        "        # x: (batch_size, 24, 24, 64)\n",
        "        x = F.max_pool2d(x, 2) # 크기를 절반으로 감소\n",
        "        # x: (batch_size, 12, 12, 64)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # x: (batch_size, 9216)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        # x: (batch_size, 128)\n",
        "        x = self.fc2(x)\n",
        "        # x: (batch_size, 10)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Model Training Libraries</b>"
      ],
      "metadata": {
        "id": "GzRC0OpvbK7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습할 모델(model), 사용할 장치(device): 보통 GPU, 어떤 데이터로 학습할지(train_loader)\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    # 10개의 클래스를 가지므로, cross-entropy 손실(loss)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.train() # 모델을 학습 모드로 변경\n",
        "    # 매 배치 단위로 데이터를 확인\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # 입력 이미지와 정답 레이블을 GPU로 보내주기\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad() # 모델의 가중치 기울기 초기화\n",
        "        # 모델에 입력 이미지를 넣은 뒤에 손실(loss)을 계산\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        # 역전파(back-propagation)\n",
        "        loss.backward()\n",
        "        optimizer.step() # 모델의 가중치 업데이트\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    # 10개의 클래스를 가지므로, cross-entropy 손실(loss)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.eval() # 모델을 학습 모드로 변경\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    # 모델을 학습하지 않고, 단순히 평가만 할 것이기 때문에 기울기 계산 X\n",
        "    with torch.no_grad():\n",
        "        # 매 배치 단위로 데이터를 확인\n",
        "        for data, target in test_loader:\n",
        "            # 입력 이미지와 정답 레이블을 GPU로 보내주기\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # 모델에 입력 이미지를 넣은 뒤에 정확도(accuracy) 계산\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "RVJ2pJe5bNTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Define the Data Loader</b>"
      ],
      "metadata": {
        "id": "jLRKHbKvecuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 연구 목적의 상황과 다르게, 배포된 모델에 사람들이 입력 진행\n",
        "train_transform = transforms.Compose([\n",
        "    # add random transformations to the image\n",
        "    # 다양한 각도와 크기에 대하여 강건할(robust) 필요가 있다.\n",
        "    transforms.RandomAffine( # 랜덤하게 이미지를 변환\n",
        "        degrees=10,\n",
        "        translate=(0.0, 0.2),\n",
        "        scale=(0.5, 1.2),\n",
        "        shear=(-10, 10, -10, 10)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# 테스트할 때는 입력 받은 이미지를 그대로 모델에 넣어주기\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, transform=test_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "ZTZCdVsBegY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f9b27b-9780-45c6-a241-8596836e58d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 262633754.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 108253524.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 146541751.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2442062.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Preview Dataset</b>"
      ],
      "metadata": {
        "id": "RmzA6pJff3bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습할 이미지가 어떻게 생겼는지 시각화\n",
        "inputs_batch, labels_batch = next(iter(train_loader))\n",
        "grid = torchvision.utils.make_grid(inputs_batch, nrow=40, pad_value=1)\n",
        "torchvision.utils.save_image(grid, 'inputs_batch_preview.png')"
      ],
      "metadata": {
        "id": "Zi60K0Tnf5oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Run the Program</b>"
      ],
      "metadata": {
        "id": "p1VBTPfCc1BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 실험할 때마다 결과가 달라지는 걸 원하지 않으므로\n",
        "# 재현성(reproduciability)을 위해 시드(seed) 값 설정\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "# GPU로 모델을 보내주어 학습할 것이기 때문에\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# 실제로 학습할 모델을 초기화\n",
        "model = Net().to(device)\n",
        "# 학습할 때 사용할 최적화(optimizer) 도구\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
        "\n",
        "# 학습 진행\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "# <테스트 정확도가 낮을 수 있음>\n",
        "# 이유: 테스트 데이터셋은 변형이 없는 올곧은 데이터로만 구성\n",
        "# 우리는 현실 세계의 배포를 위해 데이터 증진을 강하게 적용\n",
        "torch.save(model.state_dict(), \"pytorch_model.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kQh-Is6c2fR",
        "outputId": "02cb2077-3a79-4bb9-d38b-bc1c10a72952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306831\n",
            "Train Epoch: 1 [5120/60000 (8%)]\tLoss: 2.024874\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.779984\n",
            "Train Epoch: 1 [15360/60000 (25%)]\tLoss: 1.284031\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.940633\n",
            "Train Epoch: 1 [25600/60000 (42%)]\tLoss: 0.585521\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.576369\n",
            "Train Epoch: 1 [35840/60000 (59%)]\tLoss: 0.430626\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.542780\n",
            "Train Epoch: 1 [46080/60000 (76%)]\tLoss: 0.502130\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.337561\n",
            "Train Epoch: 1 [56320/60000 (93%)]\tLoss: 0.272409\n",
            "\n",
            "Test set: Average loss: 0.0004, Accuracy: 8716/10000 (87%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.604868\n",
            "Train Epoch: 2 [5120/60000 (8%)]\tLoss: 0.322840\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.304766\n",
            "Train Epoch: 2 [15360/60000 (25%)]\tLoss: 0.276149\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.235711\n",
            "Train Epoch: 2 [25600/60000 (42%)]\tLoss: 0.281260\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.245812\n",
            "Train Epoch: 2 [35840/60000 (59%)]\tLoss: 0.213840\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.194724\n",
            "Train Epoch: 2 [46080/60000 (76%)]\tLoss: 0.292050\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.276832\n",
            "Train Epoch: 2 [56320/60000 (93%)]\tLoss: 0.188764\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9786/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.158011\n",
            "Train Epoch: 3 [5120/60000 (8%)]\tLoss: 0.146963\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.151104\n",
            "Train Epoch: 3 [15360/60000 (25%)]\tLoss: 0.187805\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.116635\n",
            "Train Epoch: 3 [25600/60000 (42%)]\tLoss: 0.181246\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.133331\n",
            "Train Epoch: 3 [35840/60000 (59%)]\tLoss: 0.156640\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.138808\n",
            "Train Epoch: 3 [46080/60000 (76%)]\tLoss: 0.126312\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.123357\n",
            "Train Epoch: 3 [56320/60000 (93%)]\tLoss: 0.154780\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9833/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.153349\n",
            "Train Epoch: 4 [5120/60000 (8%)]\tLoss: 0.127807\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.135025\n",
            "Train Epoch: 4 [15360/60000 (25%)]\tLoss: 0.106537\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.101835\n",
            "Train Epoch: 4 [25600/60000 (42%)]\tLoss: 0.120259\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.116172\n",
            "Train Epoch: 4 [35840/60000 (59%)]\tLoss: 0.185119\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.127105\n",
            "Train Epoch: 4 [46080/60000 (76%)]\tLoss: 0.162261\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.157508\n",
            "Train Epoch: 4 [56320/60000 (93%)]\tLoss: 0.135657\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9799/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.137863\n",
            "Train Epoch: 5 [5120/60000 (8%)]\tLoss: 0.139323\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.140646\n",
            "Train Epoch: 5 [15360/60000 (25%)]\tLoss: 0.130380\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.157129\n",
            "Train Epoch: 5 [25600/60000 (42%)]\tLoss: 0.166474\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.126307\n",
            "Train Epoch: 5 [35840/60000 (59%)]\tLoss: 0.127951\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.116605\n",
            "Train Epoch: 5 [46080/60000 (76%)]\tLoss: 0.093847\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.112052\n",
            "Train Epoch: 5 [56320/60000 (93%)]\tLoss: 0.090819\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 9848/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.078922\n",
            "Train Epoch: 6 [5120/60000 (8%)]\tLoss: 0.105878\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.091556\n",
            "Train Epoch: 6 [15360/60000 (25%)]\tLoss: 0.145207\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.105219\n",
            "Train Epoch: 6 [25600/60000 (42%)]\tLoss: 0.098489\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.096109\n",
            "Train Epoch: 6 [35840/60000 (59%)]\tLoss: 0.117660\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.115054\n",
            "Train Epoch: 6 [46080/60000 (76%)]\tLoss: 0.106793\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.125056\n",
            "Train Epoch: 6 [56320/60000 (93%)]\tLoss: 0.104136\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 9882/10000 (99%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.087693\n",
            "Train Epoch: 7 [5120/60000 (8%)]\tLoss: 0.117160\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.069991\n",
            "Train Epoch: 7 [15360/60000 (25%)]\tLoss: 0.109667\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.116048\n",
            "Train Epoch: 7 [25600/60000 (42%)]\tLoss: 0.113281\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.093026\n",
            "Train Epoch: 7 [35840/60000 (59%)]\tLoss: 0.107451\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.129866\n",
            "Train Epoch: 7 [46080/60000 (76%)]\tLoss: 0.106704\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.107507\n",
            "Train Epoch: 7 [56320/60000 (93%)]\tLoss: 0.094592\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 9874/10000 (99%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.120802\n",
            "Train Epoch: 8 [5120/60000 (8%)]\tLoss: 0.061235\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.068753\n",
            "Train Epoch: 8 [15360/60000 (25%)]\tLoss: 0.143819\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.132609\n",
            "Train Epoch: 8 [25600/60000 (42%)]\tLoss: 0.130627\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.111095\n",
            "Train Epoch: 8 [35840/60000 (59%)]\tLoss: 0.091951\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.097836\n",
            "Train Epoch: 8 [46080/60000 (76%)]\tLoss: 0.129470\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.067581\n",
            "Train Epoch: 8 [56320/60000 (93%)]\tLoss: 0.067953\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 9886/10000 (99%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.170640\n",
            "Train Epoch: 9 [5120/60000 (8%)]\tLoss: 0.068933\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.105947\n",
            "Train Epoch: 9 [15360/60000 (25%)]\tLoss: 0.065229\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.097973\n",
            "Train Epoch: 9 [25600/60000 (42%)]\tLoss: 0.112510\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.071922\n",
            "Train Epoch: 9 [35840/60000 (59%)]\tLoss: 0.084410\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.086147\n",
            "Train Epoch: 9 [46080/60000 (76%)]\tLoss: 0.077520\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.112521\n",
            "Train Epoch: 9 [56320/60000 (93%)]\tLoss: 0.091933\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 9886/10000 (99%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.119964\n",
            "Train Epoch: 10 [5120/60000 (8%)]\tLoss: 0.091615\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.091124\n",
            "Train Epoch: 10 [15360/60000 (25%)]\tLoss: 0.134764\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.076388\n",
            "Train Epoch: 10 [25600/60000 (42%)]\tLoss: 0.078205\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.111946\n",
            "Train Epoch: 10 [35840/60000 (59%)]\tLoss: 0.083746\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.096868\n",
            "Train Epoch: 10 [46080/60000 (76%)]\tLoss: 0.083625\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.089934\n",
            "Train Epoch: 10 [56320/60000 (93%)]\tLoss: 0.073480\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 9893/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>Convert to ONNX Model</b>"
      ],
      "metadata": {
        "id": "ImHZeFakdGwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ONNX 파일로 내보내기 위해서 ONNX 라이브러리 설치\n",
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX4Q9vZok_cP",
        "outputId": "c57c0ae8-0c7f-42f3-e8fb-7b8b46aa1bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 오닉스(onnx) 배포 목적의 코드 작성\n",
        "MEAN = 0.1307 # 원래 데이터 로더에 있던 코드\n",
        "STANDARD_DEVIATION = 0.3081 # 원래 데이터 로더에 있던 코드\n",
        "\n",
        "\n",
        "class InferenceNet280RGBA(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(InferenceNet280RGBA, self).__init__()\n",
        "    # 입력 채널: 1, 출력 채널(커널의 개수): 32, 커널 크기: 3, stride: 1\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
        "    # 입력 채널: 32, 출력 채널(커널의 개수): 64, 커널 크기: 3, stride: 1\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
        "    self.fc1 = nn.Linear(9216, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # 데이터 전처리 부분이 forward() 함수 앞쪽에 존재\n",
        "    # <핵심> 데이터 전처리를 여기에 넣음\n",
        "    # 웹 사이트의 JavaScript 입력 이미지 크기가 (280 X 280 X 4)\n",
        "    # 채널이 4인 이유는? (RGBA) 이므로\n",
        "    x = x.reshape(280, 280, 4)\n",
        "    # 흑백 이미지로 만드는 코드(alpha 채널만 고려)\n",
        "    # unsqueeze(2)라고 단순히 사용하면 axes 관련 오류 → ONNX 버전 문제\n",
        "    # x = x[:,:,3] → array size 관련 오류\n",
        "    x = torch.narrow(x, dim=2, start=3, length=1)\n",
        "    # PyTorch Vision의 입력은 항상 다음과 같다.\n",
        "    # (batch_size, channel_size, width, height)\n",
        "    x = x.reshape(1, 1, 280, 280)\n",
        "    # 학습한 모델은 (28 X 28)의 크기를 받기 때문에 조절\n",
        "    x = F.avg_pool2d(x, kernel_size=10, stride=10, padding=0)\n",
        "    x = x / 255 # PyTorch는 [0, 1]의 값만 받으므로\n",
        "    # 정규화(normalization)\n",
        "    x = (x - MEAN) / STANDARD_DEVIATION\n",
        "\n",
        "    # x: (batch_size, 28, 28, 1)\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    # x: (batch_size, 26, 26, 32)\n",
        "    x = self.conv2(x)\n",
        "    # x: (batch_size, 24, 24, 64)\n",
        "    x = F.max_pool2d(x, kernel_size=2)\n",
        "    # x: (batch_size, 12, 12, 64)\n",
        "    x = torch.flatten(x, 1)\n",
        "    # x: (batch_size, 9216)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    # x: (batch_size, 128)\n",
        "    x = self.fc2(x)\n",
        "    # x: (batch_size, 10)\n",
        "    # 배포할 때는 확률(probability)을 뱉는 것이 이상적\n",
        "    # 소프트맥스(softmax)를 거친 결과를 반환\n",
        "    output = F.softmax(x, dim=1)\n",
        "    return output"
      ],
      "metadata": {
        "id": "LY1DMzZFdw3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 추론(inference) 목적의 네트워크를 초기화한다.\n",
        "pytorch_model = InferenceNet280RGBA()\n",
        "\n",
        "# 기본적으로 model의 가중치(__init__)의 구조가 일치한다면, 불러올 수 있다.\n",
        "# forward() 함수의 형식이 달라도 정상적으로 불러오는 것이 가능하다.\n",
        "pytorch_model.load_state_dict(torch.load('pytorch_model.pt'))\n",
        "pytorch_model.eval()\n",
        "\n",
        "dummy_input = torch.zeros(280 * 280 * 4)\n",
        "\n",
        "pytorch_model(dummy_input)\n",
        "\n",
        "# 실제 ONNX 파일로 내보내기\n",
        "# [추측] 최신 opset 버전으로 내보내면 onnx.js가 거기에 호환되지 않아서 오류 발생 가능\n",
        "torch.onnx.export(pytorch_model, dummy_input, 'onnx_model_280_rgba.onnx', verbose=True, opset_version=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHYh8FrldIds",
        "outputId": "185a7c81-ec8b-498e-ee75-12255edd3882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load('onnx_model_280_rgba.onnx')\n",
        "\n",
        "print(\"Producer Name:\", onnx_model.producer_name)\n",
        "print(\"Producer Version:\", onnx_model.producer_version)\n",
        "print(\"Opset\", onnx_model.opset_import[0])\n",
        "\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH5YKfd5UO0E",
        "outputId": "03218ca2-82d0-4d61-9ea6-d196b526649b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Producer Name: pytorch\n",
            "Producer Version: 2.0.1\n",
            "Opset version: 9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"onnx_model_280_rgba.onnx\")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "x = torch.randn(280 * 280 * 4)\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")\n",
        "print(ort_outs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSW1DkbTVLZR",
        "outputId": "e92f5bfa-a946-4e8d-95ac-0155b0d781c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n",
            "[array([[4.14579030e-04, 9.98257935e-01, 5.64593938e-06, 9.65924301e-06,\n",
            "        2.34426898e-05, 1.11147587e-03, 6.49995127e-05, 1.06842905e-04,\n",
            "        2.06432432e-07, 5.15509009e-06]], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 오닉스(onnx) 배포 목적의 코드 작성\n",
        "MEAN = 0.1307 # 원래 데이터 로더에 있던 코드\n",
        "STANDARD_DEVIATION = 0.3081 # 원래 데이터 로더에 있던 코드\n",
        "\n",
        "\n",
        "class InferenceNet28RGB(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(InferenceNet28RGB, self).__init__()\n",
        "    # 입력 채널: 1, 출력 채널(커널의 개수): 32, 커널 크기: 3, stride: 1\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
        "    # 입력 채널: 32, 출력 채널(커널의 개수): 64, 커널 크기: 3, stride: 1\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
        "    self.fc1 = nn.Linear(9216, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # 데이터 전처리 부분이 forward() 함수 앞쪽에 존재\n",
        "    # <핵심> 데이터 전처리를 여기에 넣음\n",
        "    # 입력 이미지 크기가 (28 X 28 X 3)이라고 가정\n",
        "    # 흑백 이미지로 만드는 코드\n",
        "    # unsqueeze(2)라고 단순히 사용하면 axes 관련 오류\n",
        "    x = x.reshape(28, 28, 3)\n",
        "    x = torch.mean(x, dim=2)\n",
        "    # PyTorch Vision의 입력은 항상 다음과 같다.\n",
        "    # (batch_size, channel_size, width, height)\n",
        "    x = x.reshape(1, 1, 28, 28)\n",
        "    x = x / 255 # PyTorch는 [0, 1]의 값만 받으므로\n",
        "    # 정규화(normalization)\n",
        "    x = (x - MEAN) / STANDARD_DEVIATION\n",
        "\n",
        "    # x: (batch_size, 28, 28, 1)\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    # x: (batch_size, 26, 26, 32)\n",
        "    x = self.conv2(x)\n",
        "    # x: (batch_size, 24, 24, 64)\n",
        "    x = F.max_pool2d(x, kernel_size=2)\n",
        "    # x: (batch_size, 12, 12, 64)\n",
        "    x = torch.flatten(x, 1)\n",
        "    # x: (batch_size, 9216)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    # x: (batch_size, 128)\n",
        "    x = self.fc2(x)\n",
        "    # x: (batch_size, 10)\n",
        "    # 배포할 때는 확률(probability)을 뱉는 것이 이상적\n",
        "    # 소프트맥스(softmax)를 거친 결과를 반환\n",
        "    output = F.softmax(x, dim=1)\n",
        "    return output"
      ],
      "metadata": {
        "id": "sk5zCxh2HuHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 추론(inference) 목적의 네트워크를 초기화한다.\n",
        "pytorch_model = InferenceNet28RGB()\n",
        "\n",
        "# 기본적으로 model의 가중치(__init__)의 구조가 일치한다면, 불러올 수 있다.\n",
        "# forward() 함수의 형식이 달라도 정상적으로 불러오는 것이 가능하다.\n",
        "pytorch_model.load_state_dict(torch.load('pytorch_model.pt'))\n",
        "pytorch_model.eval()\n",
        "\n",
        "dummy_input = torch.zeros(28 * 28 * 3)\n",
        "\n",
        "pytorch_model(dummy_input)\n",
        "\n",
        "# 실제 ONNX 파일로 내보내기\n",
        "# [추측] 최신 opset 버전으로 내보내면 onnx.js가 거기에 호환되지 않아서 오류 발생 가능\n",
        "torch.onnx.export(pytorch_model, dummy_input, 'onnx_model_28_rgb.onnx', verbose=True, opset_version=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tddlxII9Xppo",
        "outputId": "9a5f3562-a7d8-4dcd-bf59-a73962e7f4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load('onnx_model_28_rgb.onnx')\n",
        "\n",
        "print(\"Producer Name:\", onnx_model.producer_name)\n",
        "print(\"Producer Version:\", onnx_model.producer_version)\n",
        "print(\"Opset\", onnx_model.opset_import[0])\n",
        "\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqYtDfDjVqdG",
        "outputId": "b0a1716a-2224-4c9a-99f6-5c4ae43db3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Producer Name: pytorch\n",
            "Producer Version: 2.0.1\n",
            "Opset version: 9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"onnx_model_28_rgb.onnx\")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "x = torch.randn(28 * 28 * 3)\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")\n",
        "print(ort_outs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0nWDGnyVqgH",
        "outputId": "c15fe18b-c371-47fe-9d55-dbeb3da4972b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n",
            "[array([[4.2637621e-04, 9.9819404e-01, 6.2397949e-06, 1.0554491e-05,\n",
            "        2.5494746e-05, 1.1491711e-03, 6.9381458e-05, 1.1314083e-04,\n",
            "        2.2105479e-07, 5.2984133e-06]], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load('onnx_model_2.onnx')\n",
        "\n",
        "print(\"Producer Name:\", onnx_model.producer_name)\n",
        "print(\"Producer Version:\", onnx_model.producer_version)\n",
        "print(\"Opset\", onnx_model.opset_import[0])\n",
        "\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OY01X9MXG0O",
        "outputId": "1347a13c-f95f-4ba6-9e9f-f72db3792add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Producer Name: pytorch\n",
            "Producer Version: 1.3\n",
            "Opset version: 9\n",
            "\n"
          ]
        }
      ]
    }
  ]
}